Results:

Input vs. finedtuned LLM output summary:
{'total_pairs': 207, 'mean_similarity': 0.5498513060977349, 'std_similarity': 0.2044716887615552, 'var_similarity': 0.041808671505002296, 'min_similarity': -0.07614569365978241, 'max_similarity': 0.899831235408783}

Input vs. GT output summary:
{'total_pairs': 207, 'mean_similarity': 0.5339080082693538, 'std_similarity': 0.1722666410580384, 'var_similarity': 0.029675795621419046, 'min_similarity': 0.08987681567668915, 'max_similarity': 0.8406686782836914}

GT expected output summary vs. finedtuned LLM output summary:
{'total_pairs': 207, 'mean_similarity': 0.5840896992327799, 'std_similarity': 0.20164701737054974, 'var_similarity': 0.040661519614438785, 'min_similarity': -0.06166177615523338, 'max_similarity': 0.8888267874717712}

GT expected output vs. finetuned LLM output:
{'total_pairs': 207, 'mean_similarity': 0.6357227955013514, 'std_similarity': 0.20338754246713034, 'var_similarity': 0.041366492430818746, 'min_similarity': -0.00956912524998188, 'max_similarity': 1.0}

Input vs. base LLM output:
{'total_pairs': 207, 'mean_similarity': 0.9198687024738478, 'std_similarity': 0.07691297432861212, 'var_similarity': 0.005915605620073746, 'min_similarity': 0.3862026333808899, 'max_similarity': 0.9814803600311279}

GT expected output vs. base LLM output:
{'total_pairs': 207, 'mean_similarity': 0.5541842573722779, 'std_similarity': 0.1594830557915038, 'var_similarity': 0.025434845084595908, 'min_similarity': 0.07757917791604996, 'max_similarity': 0.8375130295753479}